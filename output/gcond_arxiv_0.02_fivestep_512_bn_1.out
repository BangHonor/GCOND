Namespace(gpu_id=1, dataset='ogbn-arxiv', dis_metric='ours', epochs=1000, nlayers=0, hidden=256, lr_adj=0.01, lr_feat=0.01, lr_model=0.01, weight_decay=0.0, dropout=0.5, normalize_features=True, keep_ratio=1.0, reduction_rate=0.02, seed=1, alpha=0, debug=0, sgc=1, inner=10, outer=20, save=1, model='GCN')
pyg_data: Data(num_nodes=169343, x=[169343, 128], node_year=[169343, 1], y=[169343, 1], adj_t=[169343, 169343, nnz=1166243])
split_index: {'train': tensor([     0,      1,      2,  ..., 169145, 169148, 169251]), 'valid': tensor([   349,    357,    366,  ..., 169185, 169261, 169296]), 'test': tensor([   346,    398,    451,  ..., 169340, 169341, 169342])}
WARNING:root:The OGB package is out of date. Your version is 1.3.4, while the latest version is 1.3.5.
train val test的长度: 90941 29799 48603
size of adj_train: (90941, 90941)
edges in adj_train: 738066.0
/home/xzb/GCond/gcond_agent_transduct.py:37: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1656352660876/work/torch/csrc/utils/tensor_new.cpp:201.)
  indices = torch.tensor([np.arange(n), np.arange(n)], dtype=torch.int64)
adj_syn: (1802, 1802) feat_syn: torch.Size([1802, 128])
开始图凝聚！
Epoch 100, 梯度匹配loss_avg: 3.887108154296875
Train set results: loss= 1.3348 accuracy= 0.6436
Test set results: loss= 1.2137 accuracy= 0.6547
