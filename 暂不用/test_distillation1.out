Namespace(gpu_id=3, dataset='reddit', dis_metric='ours', epochs=1000, nlayers=2, hidden=256, lr_adj=0.1, lr_feat=0.1, lr_model=0.01, weight_decay=0.0, dropout=0.0, normalize_features=True, keep_ratio=1.0, reduction_rate=0.01, seed=1, alpha=0, debug=0, sgc=1, inner=1, outer=10, option=0, save=1, label_rate=1, r=0.01)
稀疏矩阵格式为csr sparse
将大图切分为 1 个小图
切割开始！
切割时间为 13 秒
第 0 个part：
training/val/test的size为 153932 23699 55334
labels_full: Counter({15: 28272, 3: 15181, 18: 13999, 0: 13101, 38: 12797, 23: 12146, 8: 11187, 19: 10308, 22: 8222, 27: 5962, 40: 5112, 29: 5101, 33: 4960, 10: 4928, 14: 4854, 28: 4673, 31: 4570, 26: 4239, 37: 4233, 35: 4202, 36: 4180, 21: 4066, 6: 3952, 5: 3597, 1: 3550, 34: 3429, 2: 3302, 39: 3099, 11: 2964, 30: 2846, 13: 2731, 17: 2639, 4: 2322, 9: 2246, 7: 2138, 12: 1696, 25: 1659, 20: 1596, 32: 1575, 16: 1003, 24: 328})
labels_train: Counter({15: 16563, 3: 10593, 18: 9112, 0: 8471, 23: 8155, 8: 7689, 38: 7297, 19: 7093, 22: 5415, 27: 4090, 29: 3864, 33: 3382, 40: 3374, 10: 3346, 28: 3274, 31: 3230, 14: 3137, 26: 2892, 36: 2858, 35: 2849, 37: 2838, 6: 2807, 21: 2802, 5: 2389, 1: 2362, 34: 2279, 2: 2234, 39: 2141, 11: 2010, 13: 1898, 30: 1894, 17: 1653, 4: 1576, 7: 1487, 9: 1461, 25: 1158, 12: 1131, 32: 1101, 20: 1067, 16: 724, 24: 236})
小图每个分类的节点数: {24: 2, 16: 7, 20: 10, 32: 11, 12: 11, 25: 11, 9: 14, 7: 14, 4: 15, 17: 16, 30: 18, 13: 18, 11: 20, 39: 21, 2: 22, 34: 22, 1: 23, 5: 23, 21: 28, 6: 28, 37: 28, 35: 28, 36: 28, 26: 28, 14: 31, 31: 32, 28: 32, 10: 33, 40: 33, 33: 33, 29: 38, 27: 40, 22: 54, 19: 70, 38: 72, 8: 76, 23: 81, 0: 84, 18: 91, 3: 105, 15: 165}
/home/xzb/anaconda3/envs/gd/lib/python3.9/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.NeighborSampler' is deprecated, use 'loader.NeighborSampler' instead
  warnings.warn(out)
Epoch 0, loss_avg: 4.5925346374511715
存储GCN模型成功！
Test set results on syn graph's gnn: loss= 1.1606 accuracy= 0.8764
Test: [array([0.87642318]), array([0.])]EEpoch 50, loss_avg: 1.999200839531131EEpoch 100, loss_avg: 1.966364921011576
存储GCN模型成功！
Test set results on syn graph's gnn: loss= 0.7734 accuracy= 0.9046
Test: [array([0.90461561]), array([0.])]EEpoch 150, loss_avg: 1.9474939764999761EEpoch 200, loss_avg: 2.0429149162478564
存储GCN模型成功！
Test set results on syn graph's gnn: loss= 0.7769 accuracy= 0.9061
Test: [array([0.90607944]), array([0.])]EEpoch 250, loss_avg: 2.1042040569026295EEpoch 300, loss_avg: 2.0848285209841846EEpoch 350, loss_avg: 2.0068816766506288
Epoch 400, loss_avg: 1.9998412155523533
存储GCN模型成功！
Test set results on syn graph's gnn: loss= 0.8255 accuracy= 0.8968
Test: [array([0.89680847]), array([0.])]
Epoch 450, loss_avg: 1.9715104265910823
Epoch 500, loss_avg: 1.9260240136123286
Epoch 550, loss_avg: 1.901348020972275
Epoch 600, loss_avg: 1.9397482709186833
存储GCN模型成功！
Test set results on syn graph's gnn: loss= 0.7912 accuracy= 0.8997
Test: [array([0.89971808]), array([0.])]
Epoch 650, loss_avg: 1.8996079979873286
Epoch 700, loss_avg: 1.9209255683712843
Epoch 750, loss_avg: 1.988356306494736
Epoch 800, loss_avg: 1.879563978241711
存储GCN模型成功！
Test set results on syn graph's gnn: loss= 0.8030 accuracy= 0.9004
Test: [array([0.90042289]), array([0.])]
Epoch 850, loss_avg: 1.9199153062773915
Epoch 900, loss_avg: 1.9685841071896437
Epoch 950, loss_avg: 1.8500803319419303
Epoch 1000, loss_avg: 1.8630923759646532
存储GCN模型成功！
Test set results on syn graph's gnn: loss= 0.8384 accuracy= 0.8983
Test: [array([0.89832653]), array([0.])]
最好的得到小图的迭代轮次为 200
第i个小图凝聚用时: 43700 秒
读取GCN Teacher模型成功！
开始执行TAM算法！
epoch: 20 test model
Test set results of amalgamated student model: loss= 0.5765 accuracy= 0.9122
epoch: 40 test model
Test set results of amalgamated student model: loss= 0.4325 accuracy= 0.9302
epoch: 60 test model
Test set results of amalgamated student model: loss= 0.3875 accuracy= 0.9361
epoch: 80 test model
Test set results of amalgamated student model: loss= 0.3730 accuracy= 0.9382
epoch: 120 test model
Test set results of amalgamated student model: loss= 0.3635 accuracy= 0.9387
epoch: 160 test model
Test set results of amalgamated student model: loss= 0.3639 accuracy= 0.9390
epoch: 200 test model
Test set results of amalgamated student model: loss= 0.3684 accuracy= 0.9392
epoch: 300 test model
Test set results of amalgamated student model: loss= 0.3873 accuracy= 0.9376
epoch: 400 test model
Test set results of amalgamated student model: loss= 0.4072 accuracy= 0.9361
epoch: 500 test model
Test set results of amalgamated student model: loss= 0.4245 accuracy= 0.9348
epoch: 600 test model
Test set results of amalgamated student model: loss= 0.4420 accuracy= 0.9330
epoch: 700 test model
Test set results of amalgamated student model: loss= 0.4303 accuracy= 0.9344
epoch: 800 test model
Test set results of amalgamated student model: loss= 0.4353 accuracy= 0.9345
epoch: 900 test model
Test set results of amalgamated student model: loss= 0.4415 accuracy= 0.9340
epoch: 1000 test model
Test set results of amalgamated student model: loss= 0.4472 accuracy= 0.9340
知识蒸馏时长: 584 秒
TAM算法执行结束！
蒸馏前：
Test set results of teacher model: loss= 0.7769 accuracy= 0.9061
